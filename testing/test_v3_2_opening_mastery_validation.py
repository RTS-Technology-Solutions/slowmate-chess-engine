"""
SlowMate Chess Engine v3.2 - Opening Mastery Validation Test Suite
Comprehensive test to ensure v3.2 opening improvements are working correctly
"""

import sys
import os
import time
import chess
import traceback
from typing import List, Dict, Any, Optional

# Add the parent directory to the path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.engine import SlowMateEngine
from src.core.board import Board
from src.core.opening_book import AdvancedOpeningBook


class SlowMateV32ValidationSuite:
    """Comprehensive validation test suite for SlowMate v3.2 opening improvements."""
    
    def __init__(self):
        """Initialize the test suite."""
        self.engine: Optional[SlowMateEngine] = None
        self.test_results = []
        self.failed_tests = []
        
    def log_test(self, test_name: str, passed: bool, details: str = ""):
        """Log a test result."""
        status = "PASS" if passed else "FAIL"
        result = {
            'test': test_name,
            'status': status,
            'details': details
        }
        self.test_results.append(result)
        print(f"[{status}] {test_name}: {details}")
        
        if not passed:
            self.failed_tests.append(result)
    
    def test_engine_version(self) -> bool:
        """Test 1: Engine version is correctly updated to 3.2."""
        try:
            self.engine = SlowMateEngine()
            version = self.engine.get_version()
            
            if version == "3.2":
                self.log_test("Engine Version", True, f"Version {version}")
                return True
            else:
                self.log_test("Engine Version", False, f"Expected 3.2, got {version}")
                return False
        except Exception as e:
            self.log_test("Engine Version", False, f"Exception: {e}")
            return False
    
    def test_opening_book_integration(self) -> bool:
        """Test 2: Opening book is properly integrated."""
        try:
            opening_book = self.engine.opening_book
            if opening_book is None:
                self.log_test("Opening Book Integration", False, "Opening book is None")
                return False
            
            # Test starting position
            board = chess.Board()
            move = opening_book.select_strategic_move(board)
            
            if move and move in ["e4", "d4", "Nf3", "c4", "e2e4", "d2d4", "g1f3", "c2c4"]:
                self.log_test("Opening Book Integration", True, f"Selected move: {move}")
                return True
            else:
                self.log_test("Opening Book Integration", False, f"Invalid or no move selected: {move}")
                return False
        except Exception as e:
            self.log_test("Opening Book Integration", False, f"Exception: {e}")
            return False
    
    def test_opening_move_selection(self) -> bool:
        """Test 3: Engine selects opening moves from book."""
        try:
            # Test starting position
            self.engine.set_position("startpos")
            move = self.engine.search(time_limit_ms=100)  # Quick search
            
            if move and move.uci() in ["e2e4", "d2d4", "g1f3", "c2c4"]:
                self.log_test("Opening Move Selection", True, f"Selected opening move: {move.uci()}")
                return True
            else:
                self.log_test("Opening Move Selection", False, f"Non-opening move selected: {move.uci() if move else 'None'}")
                return False
        except Exception as e:
            self.log_test("Opening Move Selection", False, f"Exception: {e}")
            return False
    
    def test_opening_evaluation_bonuses(self) -> bool:
        """Test 4: Opening principle evaluation bonuses work correctly."""
        try:
            # Test developed position vs undeveloped
            developed_fen = "rnbqkb1r/pppppppp/5n2/8/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 4 3"
            undeveloped_fen = "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 1 1"
            
            # Set up developed position
            developed_board = Board()
            developed_board.set_fen(developed_fen)
            developed_eval = self.engine.evaluator.evaluate(developed_board)
            
            # Set up undeveloped position  
            undeveloped_board = Board()
            undeveloped_board.set_fen(undeveloped_fen)
            undeveloped_eval = self.engine.evaluator.evaluate(undeveloped_board)
            
            # Developed position should have higher evaluation for White
            # Note: evaluation is from side-to-move perspective, so compare absolute values
            if abs(developed_eval - undeveloped_eval) > 5:  # Some difference expected
                self.log_test("Opening Evaluation Bonuses", True, 
                           f"Developed: {developed_eval:.2f}, Undeveloped: {undeveloped_eval:.2f} - Shows evaluation difference")
                return True
            else:
                self.log_test("Opening Evaluation Bonuses", False,
                           f"Developed: {developed_eval:.2f}, Undeveloped: {undeveloped_eval:.2f} - No significant difference")
                return False
        except Exception as e:
            self.log_test("Opening Evaluation Bonuses", False, f"Exception: {e}")
            return False
    
    def test_center_control_bonus(self) -> bool:
        """Test 5: Center control gives evaluation bonus."""
        try:
            # Position with central pawns
            central_fen = "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
            # Position without central pawns
            flank_fen = "rnbqkbnr/pp1ppppp/8/2p5/1P6/8/P1PPPPPP/RNBQKBNR w KQkq - 0 2"
            
            central_board = Board()
            central_board.set_fen(central_fen)
            central_eval = self.engine.evaluator.evaluate(central_board)
            
            flank_board = Board()
            flank_board.set_fen(flank_fen)
            flank_eval = self.engine.evaluator.evaluate(flank_board)
            
            # Central control should be better
            if abs(central_eval) < abs(flank_eval) + 10:  # Allow for some variance
                self.log_test("Center Control Bonus", True, 
                           f"Central: {central_eval:.2f}, Flank: {flank_eval:.2f}")
                return True
            else:
                self.log_test("Center Control Bonus", False,
                           f"Central: {central_eval:.2f}, Flank: {flank_eval:.2f} - center not preferred")
                return False
        except Exception as e:
            self.log_test("Center Control Bonus", False, f"Exception: {e}")
            return False
    
    def test_strategic_repertoire(self) -> bool:
        """Test 6: Strategic repertoire selection works."""
        try:
            opening_book = self.engine.opening_book
            
            # Test different strategic styles
            board = chess.Board()
            
            # Test multiple move selections to see variety
            moves_selected = set()
            for _ in range(10):
                move = opening_book.select_strategic_move(board, "V7P3R")
                if move:
                    moves_selected.add(move)
            
            if len(moves_selected) >= 2:  # Should have some variety
                self.log_test("Strategic Repertoire", True, f"Selected moves: {moves_selected}")
                return True
            else:
                self.log_test("Strategic Repertoire", False, f"Limited variety: {moves_selected}")
                return False
        except Exception as e:
            self.log_test("Strategic Repertoire", False, f"Exception: {e}")
            return False
    
    def test_anti_v7p3r_preparation(self) -> bool:
        """Test 7: Anti-V7P3R preparation is working."""
        try:
            opening_book = self.engine.opening_book
            board = chess.Board()
            
            # Test opponent-specific move selection
            v7p3r_move = opening_book.select_strategic_move(board, "V7P3R")
            generic_move = opening_book.select_strategic_move(board, "Unknown")
            
            # Both should return valid moves
            valid_moves = ["e4", "d4", "Nf3", "c4", "e2e4", "d2d4", "g1f3", "c2c4"]
            if v7p3r_move in valid_moves and generic_move in valid_moves:
                self.log_test("Anti-V7P3R Preparation", True, 
                           f"V7P3R: {v7p3r_move}, Generic: {generic_move}")
                return True
            else:
                self.log_test("Anti-V7P3R Preparation", False,
                           f"Invalid moves - V7P3R: {v7p3r_move}, Generic: {generic_move}")
                return False
        except Exception as e:
            self.log_test("Anti-V7P3R Preparation", False, f"Exception: {e}")
            return False
    
    def test_performance_regression(self) -> bool:
        """Test 8: No significant performance regression."""
        try:
            start_time = time.time()
            
            # Test search speed with opening book
            self.engine.set_position("startpos")
            move = self.engine.search(time_limit_ms=1000)
            
            end_time = time.time()
            search_time = end_time - start_time
            
            # Should complete within reasonable time (allowing for book lookup)
            if search_time < 1.5 and move:  # Book moves should be fast
                self.log_test("Performance Regression", True, f"Search time: {search_time:.3f}s, Move: {move.uci()}")
                return True
            else:
                self.log_test("Performance Regression", False,
                           f"Slow search: {search_time:.3f}s, Move: {move.uci() if move else 'None'}")
                return False
        except Exception as e:
            self.log_test("Performance Regression", False, f"Exception: {e}")
            return False
    
    def test_uci_compatibility(self) -> bool:
        """Test 9: UCI protocol still works correctly."""
        try:
            # Test UCI identification
            if hasattr(self.engine, 'uci') and self.engine.uci:
                # Basic UCI should still work
                self.log_test("UCI Compatibility", True, "UCI protocol accessible")
                return True
            else:
                self.log_test("UCI Compatibility", False, "UCI protocol not accessible")
                return False
        except Exception as e:
            self.log_test("UCI Compatibility", False, f"Exception: {e}")
            return False
    
    def run_all_tests(self) -> Dict[str, Any]:
        """Run all validation tests."""
        print("ğŸš€ SlowMate Chess Engine v3.2 - Opening Mastery Validation")
        print("=" * 70)
        print("Testing enhanced opening book and evaluation improvements")
        print()
        
        tests = [
            self.test_engine_version,
            self.test_opening_book_integration,
            self.test_opening_move_selection,
            self.test_opening_evaluation_bonuses,
            self.test_center_control_bonus,
            self.test_strategic_repertoire,
            self.test_anti_v7p3r_preparation,
            self.test_performance_regression,
            self.test_uci_compatibility
        ]
        
        passed = 0
        for test in tests:
            try:
                if test():
                    passed += 1
            except Exception as e:
                print(f"[FAIL] {test.__name__}: Unexpected error: {e}")
                traceback.print_exc()
        
        print()
        print("=" * 70)
        print("VALIDATION SUMMARY")
        print("=" * 70)
        
        success_rate = (passed / len(tests)) * 100
        print(f"Tests Passed: {passed}/{len(tests)} ({success_rate:.1f}%)")
        
        if passed == len(tests):
            print("\nğŸ¯ STATUS: âœ… ALL TESTS PASSED - V3.2 READY FOR COMPETITION")
            print("ğŸ† Opening improvements successfully integrated")
            print("ğŸ® Ready for tournament testing against V7P3R")
            production_ready = True
        elif passed >= len(tests) * 0.8:
            print(f"\nâš ï¸  STATUS: ğŸŸ¡ MOSTLY READY - {len(tests) - passed} issues to fix")
            print("ğŸ”§ Minor issues detected, but should be tournament viable")
            production_ready = True
        else:
            print(f"\nâŒ STATUS: ğŸ”´ NOT READY - {len(tests) - passed} critical issues")
            print("ğŸš¨ Major issues detected, fix before tournament deployment")
            production_ready = False
        
        if self.failed_tests:
            print("\nğŸ“‹ Failed Tests:")
            for test in self.failed_tests:
                print(f"  - {test['test']}: {test['details']}")
        
        return {
            'total_tests': len(tests),
            'passed_tests': passed,
            'success_rate': success_rate,
            'production_ready': production_ready,
            'failed_tests': self.failed_tests
        }


def main():
    """Main test execution."""
    test_suite = SlowMateV32ValidationSuite()
    results = test_suite.run_all_tests()
    
    # Exit with appropriate code
    if results['production_ready']:
        print(f"\nğŸš€ SlowMate v3.2 validated and ready!")
        print("ğŸ¯ Target: Defeat V7P3R through superior opening preparation")
        sys.exit(0)  # Success
    else:
        print(f"\nâš ï¸  Fix issues before tournament deployment")
        sys.exit(1)  # Failure


if __name__ == "__main__":
    main()